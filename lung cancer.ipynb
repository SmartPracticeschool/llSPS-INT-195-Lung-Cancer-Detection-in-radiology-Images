{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Steps for convolution neural networks \n",
    "1)import libraries \n",
    "2)initialize the model\n",
    "3)add the con 2nd layer\n",
    "4)add max\n",
    "5)add flattening layer\n",
    "6)add hidden layer on ann\n",
    "7)add op layer of cnn\n",
    "8)import the dataset \n",
    "9)you have to apply image preprocessing techniques \n",
    "10)compile\n",
    "11)predict \n",
    "12)save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#initialize the model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3)add the con 2nd layer\n",
    "\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4)add max\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5)add flattening layer\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#6)add hidden layer on ann\n",
    "model.add(Dense(output_dim=128,init=\"uniform\",activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#7)add op layer of cnn\n",
    "model.add(Dense(output_dim=1,init=\"uniform\",activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(r\"D:\\Project\\Dataset\\trainset\",target_size=(64,64),batch_size=32,class_mode=\"binary\")\n",
    "x_test=test_datagen.flow_from_directory(r\"D:\\Project\\Dataset\\testset\",target_size=(64,64),batch_size=32,class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cancer': 0, 'NonCancer': 1}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 0.4124 - acc: 0.8122 - val_loss: 0.1976 - val_acc: 0.9240\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.1403 - acc: 0.9557 - val_loss: 0.0313 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0437 - acc: 0.9843 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.0126 - acc: 0.9984 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.0084 - acc: 0.9994 - val_loss: 8.7651e-04 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 0.0059 - acc: 0.9997 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.0041 - acc: 0.9994 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 16s 156ms/step - loss: 0.0065 - acc: 0.9975 - val_loss: 0.0257 - val_acc: 0.9750\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 16s 156ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 7.1986e-05 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 5.0064e-04 - acc: 1.0000 - val_loss: 8.2901e-05 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 4.3861e-04 - acc: 1.0000 - val_loss: 3.6908e-05 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 3.1996e-04 - acc: 1.0000 - val_loss: 3.3215e-05 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 2.6367e-04 - acc: 1.0000 - val_loss: 3.4132e-05 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 4.0365e-04 - acc: 1.0000 - val_loss: 4.7160e-05 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 1.5579e-04 - acc: 1.0000 - val_loss: 2.1519e-05 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 1.4307e-04 - acc: 1.0000 - val_loss: 2.2790e-05 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 1.1489e-04 - acc: 1.0000 - val_loss: 8.8911e-06 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 1.3287e-04 - acc: 1.0000 - val_loss: 8.5048e-06 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 5.8745e-04 - acc: 1.0000 - val_loss: 1.8056e-05 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.1108 - acc: 0.9619 - val_loss: 0.0164 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0283 - acc: 0.9934 - val_loss: 6.5452e-04 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.0037 - acc: 0.9997 - val_loss: 9.0818e-05 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 2.7221e-05 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 1.3323e-05 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 5.0489e-04 - acc: 1.0000 - val_loss: 1.0122e-05 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 6.6355e-04 - acc: 1.0000 - val_loss: 2.8929e-05 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 2.7788e-04 - acc: 1.0000 - val_loss: 7.6752e-06 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 2.1206e-04 - acc: 1.0000 - val_loss: 3.9393e-06 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.0017 - acc: 0.9997 - val_loss: 1.1037e-05 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.0049 - acc: 0.9991 - val_loss: 1.0804e-04 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 3.2108e-04 - acc: 1.0000 - val_loss: 6.5176e-06 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 5.2386e-04 - acc: 0.9997 - val_loss: 3.3878e-05 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 1.1796e-04 - acc: 1.0000 - val_loss: 1.5067e-05 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 1.9700e-04 - acc: 1.0000 - val_loss: 1.5129e-05 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 8.7272e-05 - acc: 1.0000 - val_loss: 1.4459e-05 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 1.6576e-04 - acc: 1.0000 - val_loss: 8.0771e-06 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 9.6414e-05 - acc: 1.0000 - val_loss: 3.5947e-05 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 8.0350e-05 - acc: 1.0000 - val_loss: 1.8268e-05 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 4.7425e-05 - acc: 1.0000 - val_loss: 8.6994e-06 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 6.7207e-05 - acc: 1.0000 - val_loss: 1.3447e-05 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 4.8350e-05 - acc: 1.0000 - val_loss: 8.0012e-06 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 3.4116e-05 - acc: 1.0000 - val_loss: 4.7438e-06 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 3.0547e-05 - acc: 1.0000 - val_loss: 4.5009e-06 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 3.0519e-05 - acc: 1.0000 - val_loss: 1.7175e-06 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 2.7243e-05 - acc: 1.0000 - val_loss: 2.3943e-06 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 2.7711e-05 - acc: 1.0000 - val_loss: 3.3860e-06 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 2.2755e-05 - acc: 1.0000 - val_loss: 2.7160e-06 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 3.1711e-05 - acc: 1.0000 - val_loss: 2.0986e-06 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 1.8661e-05 - acc: 1.0000 - val_loss: 1.7338e-06 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 2.3287e-05 - acc: 1.0000 - val_loss: 3.1226e-06 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 1.5861e-05 - acc: 1.0000 - val_loss: 1.7745e-06 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 1.8527e-05 - acc: 1.0000 - val_loss: 3.1654e-06 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 3.4890e-05 - acc: 1.0000 - val_loss: 4.1799e-06 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 1.4516e-05 - acc: 1.0000 - val_loss: 2.6087e-06 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 1.3000e-05 - acc: 1.0000 - val_loss: 1.3588e-06 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 1.1333e-05 - acc: 1.0000 - val_loss: 1.9813e-06 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 1.4555e-05 - acc: 1.0000 - val_loss: 9.7421e-07 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 1.1461e-05 - acc: 1.0000 - val_loss: 1.2986e-06 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 1.1013e-05 - acc: 1.0000 - val_loss: 1.0956e-06 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 1.2055e-05 - acc: 1.0000 - val_loss: 8.3707e-07 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 9.2294e-06 - acc: 1.0000 - val_loss: 1.2291e-06 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 1.1112e-05 - acc: 1.0000 - val_loss: 7.1373e-07 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 7.8104e-06 - acc: 1.0000 - val_loss: 8.7237e-07 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 17s 170ms/step - loss: 6.8324e-06 - acc: 1.0000 - val_loss: 5.9587e-07 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 7.7604e-06 - acc: 1.0000 - val_loss: 7.1257e-07 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 7.5876e-06 - acc: 1.0000 - val_loss: 6.7807e-07 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 7.2277e-06 - acc: 1.0000 - val_loss: 9.6931e-07 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 4.7566e-06 - acc: 1.0000 - val_loss: 7.6383e-07 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 5.2019e-06 - acc: 1.0000 - val_loss: 7.7464e-07 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 4.4850e-06 - acc: 1.0000 - val_loss: 6.2868e-07 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 5.4398e-06 - acc: 1.0000 - val_loss: 7.6569e-07 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 6.5003e-06 - acc: 1.0000 - val_loss: 3.2133e-07 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 8.1867e-06 - acc: 1.0000 - val_loss: 5.5140e-07 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 3.8188e-06 - acc: 1.0000 - val_loss: 6.5189e-07 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 3.7800e-06 - acc: 1.0000 - val_loss: 7.4885e-07 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 2.8635e-06 - acc: 1.0000 - val_loss: 3.9729e-07 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 5.5573e-06 - acc: 1.0000 - val_loss: 1.4073e-06 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 3.2801e-06 - acc: 1.0000 - val_loss: 4.9771e-07 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 3.3615e-06 - acc: 1.0000 - val_loss: 5.4163e-07 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 3.1012e-06 - acc: 1.0000 - val_loss: 4.8526e-07 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 2.6603e-06 - acc: 1.0000 - val_loss: 5.8989e-07 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 4.2206e-06 - acc: 1.0000 - val_loss: 3.7228e-07 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 6.8994e-06 - acc: 1.0000 - val_loss: 5.2578e-07 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 2.6823e-06 - acc: 1.0000 - val_loss: 8.5913e-07 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 2.7088e-06 - acc: 1.0000 - val_loss: 7.5208e-07 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 2.5079e-06 - acc: 1.0000 - val_loss: 9.1865e-07 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 2.9037e-06 - acc: 1.0000 - val_loss: 2.3369e-07 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 1.8474e-06 - acc: 1.0000 - val_loss: 3.4341e-07 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 2.6035e-06 - acc: 1.0000 - val_loss: 3.7969e-07 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 1.8389e-06 - acc: 1.0000 - val_loss: 7.0473e-07 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 1.2872e-06 - acc: 1.0000 - val_loss: 3.8109e-07 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 2.7239e-06 - acc: 1.0000 - val_loss: 1.9680e-07 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 1.3739e-06 - acc: 1.0000 - val_loss: 5.8629e-07 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 2.2539e-06 - acc: 1.0000 - val_loss: 7.1386e-07 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 1.6199e-06 - acc: 1.0000 - val_loss: 4.8858e-07 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 1.0659e-06 - acc: 1.0000 - val_loss: 3.1000e-07 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 1.0394e-06 - acc: 1.0000 - val_loss: 4.9218e-07 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 8.8782e-07 - acc: 1.0000 - val_loss: 4.4805e-07 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 1.1368e-06 - acc: 1.0000 - val_loss: 5.3833e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fbf7ba0b48>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=100,epochs=100,validation_data=x_test,validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"lungcancer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
